{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMPRANAV/PID-Pipe-and-Instrumentation-Diagram-Digitalization/blob/main/PID_Detcction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr4ervuljQ5v",
        "outputId": "be0a255d-5391-47e0-d740-d021e2cafafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PID_Symbol_Detection'...\n",
            "remote: Enumerating objects: 490, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 490 (delta 38), reused 36 (delta 36), pack-reused 447 (from 2)\u001b[K\n",
            "Receiving objects: 100% (490/490), 147.16 MiB | 22.33 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mgupta70/PID_Symbol_Detection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnIo-xruklgs",
        "outputId": "2fe39e1d-f2d4-4b91-9f88-b50b6fa53d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/PID_Symbol_Detection\n"
          ]
        }
      ],
      "source": [
        "%cd PID_Symbol_Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMfPZ_I3l9WI",
        "outputId": "36a83623-87d9-40a9-c232-af6deb897e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sed: can't read requirements.txt: No such file or directory\n",
            "Ignoring pywin32: markers 'sys_platform == \"win32\"' don't match your environment\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Remove pywin32 completely\n",
        "!sed -i '/pywin32/d' requirements.txt\n",
        "\n",
        "# Step 2: (Optional) If you want to keep it only for Windows\n",
        "!echo 'pywin32==310; sys_platform == \"win32\"' >> requirements.txt\n",
        "\n",
        "# Step 3: Ensure numpy is set to a Colab-compatible version\n",
        "!sed -i 's/^numpy==.*/numpy==1.26.4/' requirements.txt\n",
        "# 🔹 Fix torch\n",
        "!sed -i 's/torch==2.3.1+cu121/torch==2.3.1/' requirements.txt\n",
        "\n",
        "# 🔹 Fix torchaudio\n",
        "!sed -i 's/torchaudio==2.3.1+cu121/torchaudio==2.3.1/' requirements.txt\n",
        "\n",
        "# 🔹 Fix torchvision (if present)\n",
        "!sed -i 's/torchvision==0.18.1+cu121/torchvision==0.18.1/' requirements.txt\n",
        "\n",
        "# 🔹 Ensure numpy is compatible with Colab's Python\n",
        "!sed -i 's/^numpy==.*/numpy==1.26.4/' requirements.txt\n",
        "# Step 4: Reinstall\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5T_5SSfsaU6",
        "outputId": "86997eeb-d9af-42af-8242-34807d3c5bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'PID_Symbol_Detection'\n",
            "/content/PID_Symbol_Detection\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "Preparing data for class-agnostic detection...\n",
            "2025-08-17 23:41:07,039 - INFO - ✅ saved class-agnostic labels for '0.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "2025-08-17 23:41:07,040 - INFO - ✅ saved class-agnostic labels for '1.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "2025-08-17 23:41:07,040 - INFO - ✅ saved class-agnostic labels for '2.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "2025-08-17 23:41:07,041 - INFO - ✅ saved class-agnostic labels for '3.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "2025-08-17 23:41:07,041 - INFO - ✅ saved class-agnostic labels for '4.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "2025-08-17 23:41:07,042 - INFO - ✅ saved class-agnostic labels for '5.txt' at 'data/raw/labels_class_agnostic' folder\n",
            "✅ Successfully extracted patches for image: 0.jpg\n",
            "✅ Successfully extracted patches for image: 1.jpg\n",
            "✅ Successfully extracted patches for image: 2.jpg\n",
            "✅ Successfully extracted patches for image: 3.jpg\n",
            "✅ Successfully extracted patches for image: 4.jpg\n",
            "✅ Successfully extracted patches for image: 5.jpg\n",
            "2025-08-17 23:41:09,689 - INFO - Created YOLO dataset structure in data/processed/stage_1/yolo_class_agnostic\n",
            "2025-08-17 23:41:09,810 - INFO - Created dataset.yaml at: data/processed/stage_1/yolo_class_agnostic/dataset.yaml\n",
            "2025-08-17 23:41:09,810 - INFO - YOLO dataset creation complete.\n",
            "Training class-agnostic detection model...\n",
            "New https://pypi.org/project/ultralytics/8.3.179 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.115 🚀 Python-3.11.13 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=models/base_yolo_models/yolov8n.pt, data=data/processed/stage_1/yolo_class_agnostic/dataset.yaml, epochs=2, time=None, patience=100, batch=2, imgsz=(640, 640), save=True, save_period=-1, cache=False, device=cpu, workers=8, project=models/stage1/class_agnostic, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=models/stage1/class_agnostic/train3\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "WARNING ⚠️ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1716.2±510.4 MB/s, size: 95.2 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/PID_Symbol_Detection/data/processed/stage_1/yolo_class_agnostic/labels/train.cache... 112 images, 22 backgrounds, 0 corrupt: 100% 112/112 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1755.5±306.0 MB/s, size: 89.3 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/PID_Symbol_Detection/data/processed/stage_1/yolo_class_agnostic/labels/val.cache... 28 images, 7 backgrounds, 0 corrupt: 100% 28/28 [00:00<?, ?it/s]\n",
            "Plotting labels to models/stage1/class_agnostic/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mmodels/stage1/class_agnostic/train3\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/2         0G      1.159      3.049      1.049         15        640: 100% 56/56 [01:24<00:00,  1.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:08<00:00,  1.19s/it]\n",
            "                   all         28        108      0.947      0.165       0.67      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/2         0G      1.075      2.212      1.014          3        640: 100% 56/56 [01:29<00:00,  1.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:07<00:00,  1.10s/it]\n",
            "                   all         28        108      0.879      0.603       0.79      0.589\n",
            "\n",
            "2 epochs completed in 0.053 hours.\n",
            "Optimizer stripped from models/stage1/class_agnostic/train3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from models/stage1/class_agnostic/train3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating models/stage1/class_agnostic/train3/weights/best.pt...\n",
            "Ultralytics 8.3.115 🚀 Python-3.11.13 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:07<00:00,  1.12s/it]\n",
            "                   all         28        108      0.878      0.597       0.79      0.589\n",
            "Speed: 4.6ms preprocess, 247.1ms inference, 0.0ms loss, 9.0ms postprocess per image\n",
            "Results saved to \u001b[1mmodels/stage1/class_agnostic/train3\u001b[0m\n",
            "2025-08-17 23:44:37,437 - INFO - Training completed successfully. Results saved to models/stage1/class_agnostic\n",
            "Stage 1 pipeline completed successfully\n"
          ]
        }
      ],
      "source": [
        "%cd PID_Symbol_Detection\n",
        "!python src/run_pipeline.py stage1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5e7I-7Qu8Cy",
        "outputId": "70bc0a3d-c90c-4279-ac65-3c010689d5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "✅ Crops saved for image: 0.jpg\n",
            "✅ Crops saved for image: 1.jpg\n",
            "✅ Crops saved for image: 2.jpg\n",
            "✅ Crops saved for image: 3.jpg\n",
            "✅ Crops saved for image: 4.jpg\n",
            "✅ Crops saved for image: 5.jpg\n",
            "✅ Support set created at: data/processed/stage_2/few_shot\n"
          ]
        }
      ],
      "source": [
        "!python src/run_pipeline.py stage2 --prepare_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcd0yJh8di9G",
        "outputId": "72dca71c-fd27-4ffc-a433-5bfb5a6ef7e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "2025-08-18 00:07:03,159 - INFO - Starting training for 2 epochs on cpu.\n",
            "2025-08-18 00:07:03,160 - INFO - Epoch 1/2\n",
            "2025-08-18 00:11:57,908 - INFO - Train Loss: 0.8079, Train Accuracy: 0.6733\n",
            "2025-08-18 00:12:07,265 - INFO - Val Loss: 0.3303, Val Accuracy: 0.9000\n",
            "2025-08-18 00:12:12,501 - INFO - Model saved at epoch 1.\n",
            "2025-08-18 00:12:13,865 - INFO - Best model saved.\n",
            "2025-08-18 00:12:13,865 - INFO - Epoch 2/2\n",
            "2025-08-18 00:17:11,357 - INFO - Train Loss: 0.7653, Train Accuracy: 0.6933\n",
            "2025-08-18 00:17:21,183 - INFO - Val Loss: 0.6663, Val Accuracy: 0.7200\n",
            "2025-08-18 00:17:28,720 - INFO - Model saved at epoch 2.\n",
            "2025-08-18 00:17:28,750 - INFO - Training history saved.\n",
            "2025-08-18 00:17:28,750 - INFO - Training finished.\n"
          ]
        }
      ],
      "source": [
        "!python src/run_pipeline.py stage2 --train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCmoSAFkeKKk",
        "outputId": "7bdb255a-eece-4c5e-f442-76cb63194f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "2025-08-18 00:20:48,938 - INFO - Loading YOLO model from models/stage1/class_agnostic/best.pt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/0.txt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/1.txt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/2.txt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/3.txt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/4.txt\n",
            "Performing prediction on 40 slices.\n",
            "YOLO annotations saved to: results/stage_1/class_agnostic/5.txt\n",
            "2025-08-18 00:23:24,339 - INFO - Stage 1 inference completed successfully.\n"
          ]
        }
      ],
      "source": [
        "!python src/run_pipeline.py stage1_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB7zor97kq8I",
        "outputId": "af1291e8-3238-454a-86a9-35d8a232ee32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/__init__.py\", line 81, in load\n",
            "    return loader.get_single_data()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/constructor.py\", line 49, in get_single_data\n",
            "    node = self.get_single_node()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 36, in get_single_node\n",
            "    document = self.compose_document()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 55, in compose_document\n",
            "    node = self.compose_node(None, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 84, in compose_node\n",
            "    node = self.compose_mapping_node(anchor)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
            "    item_value = self.compose_node(node, item_key)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 84, in compose_node\n",
            "    node = self.compose_mapping_node(anchor)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/composer.py\", line 127, in compose_mapping_node\n",
            "    while not self.check_event(MappingEndEvent):\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/parser.py\", line 98, in check_event\n",
            "    self.current_event = self.state()\n",
            "                         ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/parser.py\", line 428, in parse_block_mapping_key\n",
            "    if self.check_token(KeyToken):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/scanner.py\", line 116, in check_token\n",
            "    self.fetch_more_tokens()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/scanner.py\", line 159, in fetch_more_tokens\n",
            "    self.scan_to_next_token()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/scanner.py\", line 779, in scan_to_next_token\n",
            "    while self.peek() not in '\\0\\r\\n\\x85\\u2028\\u2029':\n",
            "          ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/reader.py\", line 87, in peek\n",
            "    def peek(self, index=0):\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PID_Symbol_Detection/src/run_pipeline.py\", line 104, in <module>\n",
            "    main() \n",
            "    ^^^^^^\n",
            "  File \"/content/PID_Symbol_Detection/src/run_pipeline.py\", line 87, in main\n",
            "    pipeline = Stage2FewShotInferencePipeline(config_path=args.config)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/PID_Symbol_Detection/src/pipeline/stage2_few_shot_inference.py\", line 17, in __init__\n",
            "    super().__init__(config_path)\n",
            "  File \"/content/PID_Symbol_Detection/src/pipeline/base.py\", line 16, in __init__\n",
            "    self.config_manager = ConfigManager(config_path)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/PID_Symbol_Detection/src/pipeline/configs/config_manager.py\", line 15, in __init__\n",
            "    self.config = self._load_config()\n",
            "                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/PID_Symbol_Detection/src/pipeline/configs/config_manager.py\", line 27, in _load_config\n",
            "    config = yaml.safe_load(file)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/__init__.py\", line 125, in safe_load\n",
            "    return load(stream, SafeLoader)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/__init__.py\", line 83, in load\n",
            "    loader.dispose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yaml/parser.py\", line 89, in dispose\n",
            "    def dispose(self):\n",
            "\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python src/run_pipeline.py stage2_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSYXPMh2liV8",
        "outputId": "733c986f-67a8-48f8-8f02-4e44813374d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'PID_Symbol_Detection'\n",
            "/content/PID_Symbol_Detection\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "2025-08-18 00:37:27,378 - INFO - Computing Stage 1 metrics\n",
            "Sheet-wise performance:  {'0.txt': {'precision': 0.9888888888888889, 'recall': 0.9888888888888889, 'f1': 0.9888888888888889}, '1.txt': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, '2.txt': {'precision': 0.9819819819819819, 'recall': 0.9819819819819819, 'f1': 0.9819819819819819}, '3.txt': {'precision': 0.9894736842105263, 'recall': 0.9894736842105263, 'f1': 0.9894736842105263}, '4.txt': {'precision': 0.992, 'recall': 1.0, 'f1': 0.9959839357429718}, '5.txt': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}\n",
            "Stage 1 metrics:\n",
            "Overall precision:  0.9920574258468996\n",
            "Overall recall:  0.9933907591802328\n",
            "Overall f1:  0.9927214151373948\n",
            "2025-08-18 00:37:27,461 - INFO - Stage 1 metrics computed successfully\n"
          ]
        }
      ],
      "source": [
        "%cd PID_Symbol_Detection\n",
        "!python src/run_pipeline.py evaluation --evaluate_stage1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTH3a5pGnHIC",
        "outputId": "39c89787-42ce-47ec-d9ec-8c3f5477aa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/src/run_pipeline.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python src/run_pipeline.py evaluation --evaluate_stage2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3XUpNYddivF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT2YDUwllbZp",
        "outputId": "0f027412-a3fd-48c4-abf3-c8e9c4eef6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.3)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.3.0 streamlit-1.48.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_wha1Mjrypn",
        "outputId": "fa012fd0-223e-4b08-b039-bdf5ea00aece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Import your trained model functions\n",
        "# from your_pipeline import run_stage1_inference, run_stage2_inference\n",
        "\n",
        "st.title(\"🔧 PID Symbol Detection\")\n",
        "st.markdown(\"Upload a P&ID diagram to detect and classify symbols\")\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"Choose a P&ID image\", type=['png', 'jpg', 'jpeg'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption=\"Uploaded P&ID\", use_column_width=True)\n",
        "\n",
        "    # Save uploaded file temporarily\n",
        "    with open(\"temp_image.jpg\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    if st.button(\"🔍 Detect Symbols\"):\n",
        "        with st.spinner(\"Analyzing image...\"):\n",
        "            try:\n",
        "                # Call your actual detection functions here\n",
        "                # stage1_results = run_stage1_inference(\"temp_image.jpg\")\n",
        "                # stage2_results = run_stage2_inference(\"temp_image.jpg\", stage1_results)\n",
        "\n",
        "                # For demo - replace with your actual results\n",
        "                st.success(\"Detection completed!\")\n",
        "\n",
        "                # Display results\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.metric(\"Symbols Found\", \"12\")\n",
        "                    st.metric(\"Confidence\", \"89%\")\n",
        "\n",
        "                with col2:\n",
        "                    st.write(\"**Detected Symbol Types:**\")\n",
        "                    st.write(\"• Valves: 4\")\n",
        "                    st.write(\"• Pumps: 3\")\n",
        "                    st.write(\"• Sensors: 5\")\n",
        "\n",
        "                # Download results\n",
        "                if st.button(\"📥 Download Results\"):\n",
        "                    # Generate results file\n",
        "                    results = {\"symbols\": [\"valve\", \"pump\", \"sensor\"]}\n",
        "                    st.download_button(\n",
        "                        label=\"Download JSON\",\n",
        "                        data=str(results),\n",
        "                        file_name=\"pid_results.json\"\n",
        "                    )\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747,
          "referenced_widgets": [
            "c3fef8f229f740a0ba5641edac015d1b",
            "23b8387316a443b389ef3e9c4d9d395c",
            "68dec885d98948449762889f32fd1a4e",
            "37220189acb54e5ca7452205e4ebdb87",
            "966ee48c8e1e4bb1b37ab165450708a9",
            "993587ebc4c94424b5e459108682a3d8",
            "9a488e4839f144b79d95bc2694f86116",
            "19604add1a9f430982b6ccc85ec17435",
            "225e91e231874ca39ad6c18433cf14d7",
            "a7a8cc3a358b4bb29736ee814359c79b",
            "a0562f67dc74495fa2b210b88274aec5"
          ]
        },
        "id": "0rX4rTVYssu5",
        "outputId": "eafa6b45-4608-4077-80ac-4f715203b6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "theme_schema%400.0.3.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3fef8f229f740a0ba5641edac015d1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8ce566c5f909baae56.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8ce566c5f909baae56.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "\n",
        "type_colors = {\n",
        "    \"valve\": \"red\",\n",
        "    \"pump\": \"blue\",\n",
        "    \"sensor\": \"green\"\n",
        "}\n",
        "\n",
        "def detect_symbols(image, detect_types):\n",
        "    if image is None:\n",
        "        return \"No image uploaded.\", image, None\n",
        "\n",
        "    # Get file name (if available)\n",
        "    file_name = getattr(image, \"filename\", None)\n",
        "\n",
        "    # Set up different mock detection output for different images\n",
        "    if file_name and \"1.jpg\" in file_name:\n",
        "        fake_detections = [\n",
        "            {\"class\": \"valve\", \"bbox\": [60, 40, 120, 80], \"confidence\": 0.93},\n",
        "            {\"class\": \"valve\", \"bbox\": [130, 90, 190, 140], \"confidence\": 0.88},\n",
        "            {\"class\": \"sensor\", \"bbox\": [300, 60, 340, 110], \"confidence\": 0.89},\n",
        "        ]\n",
        "    elif file_name and \"2.jpg\" in file_name:\n",
        "        fake_detections = [\n",
        "            {\"class\": \"pump\", \"bbox\": [200, 150, 260, 220], \"confidence\": 0.96},\n",
        "            {\"class\": \"sensor\", \"bbox\": [420, 120, 480, 180], \"confidence\": 0.82},\n",
        "        ]\n",
        "    elif file_name and \"3.jpg\" in file_name:\n",
        "        fake_detections = [\n",
        "            {\"class\": \"valve\", \"bbox\": [100, 60, 160, 120], \"confidence\": 0.85},\n",
        "            {\"class\": \"pump\", \"bbox\": [250, 200, 310, 260], \"confidence\": 0.90},\n",
        "            {\"class\": \"sensor\", \"bbox\": [400, 80, 460, 140], \"confidence\": 0.75},\n",
        "            {\"class\": \"sensor\", \"bbox\": [480, 220, 510, 270], \"confidence\": 0.80},\n",
        "        ]\n",
        "    elif file_name and \"4.jpg\" in file_name:\n",
        "        fake_detections = [\n",
        "            {\"class\": \"pump\", \"bbox\": [60, 60, 140, 140], \"confidence\": 0.92},\n",
        "            {\"class\": \"valve\", \"bbox\": [160, 200, 220, 250], \"confidence\": 0.79},\n",
        "        ]\n",
        "    else:\n",
        "        # Default detection result (other files)\n",
        "        fake_detections = [\n",
        "            {\"class\": \"valve\", \"bbox\": [60, 40, 120, 80], \"confidence\": 0.93},\n",
        "            {\"class\": \"pump\", \"bbox\": [200, 150, 260, 220], \"confidence\": 0.86},\n",
        "            {\"class\": \"sensor\", \"bbox\": [300, 60, 340, 110], \"confidence\": 0.91},\n",
        "        ]\n",
        "\n",
        "    # Filter by selected types\n",
        "    detections = [d for d in fake_detections if d['class'] in detect_types]\n",
        "\n",
        "    # Annotate image\n",
        "    annotated = image.copy()\n",
        "    draw = ImageDraw.Draw(annotated)\n",
        "    for d in detections:\n",
        "        x1, y1, x2, y2 = d[\"bbox\"]\n",
        "        color = type_colors.get(d[\"class\"], \"black\")\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "        draw.text((x1, y1 - 12), f'{d[\"class\"]} ({int(d[\"confidence\"] * 100)}%)', fill=color)\n",
        "\n",
        "    df = pd.DataFrame(detections)\n",
        "    type_counts = {t: sum(d['class'] == t for d in detections) for t in type_colors}\n",
        "    per_type_summary = \" | \".join([f\"{t.title()}: {type_counts[t]}\" for t in detect_types])\n",
        "\n",
        "    mean_conf = round(sum([d[\"confidence\"] for d in detections]) / len(detections), 2) if detections else 0\n",
        "    summary = (\n",
        "        f\"🔍 **Detection Results:**\\n\\n\"\n",
        "        f\"• **Symbols Found:** {len(detections)}\\n\"\n",
        "        f\"• **Per Type:** {per_type_summary}\\n\"\n",
        "        f\"• **Average Confidence:** {int(mean_conf * 100)}%\\n\"\n",
        "        f\"• **Types:** {', '.join(sorted(set([d['class'] for d in detections])))}\"\n",
        "    )\n",
        "    return summary, annotated, df\n",
        "\n",
        "gr.Interface(\n",
        "    fn=detect_symbols,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", image_mode=\"RGB\", label=\"Upload P&ID Diagram\"),\n",
        "        gr.CheckboxGroup(choices=[\"valve\", \"pump\", \"sensor\"], value=[\"valve\", \"pump\", \"sensor\"], label=\"Symbol Types to Detect\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Summary\"),\n",
        "        gr.Image(label=\"Processed Image\"),\n",
        "        gr.Dataframe(label=\"Detected Symbols Table\")\n",
        "    ],\n",
        "    title=\"PID Symbol Detection (Interactive Demo)\",\n",
        "    description=(\n",
        "        \"Upload a P&ID diagram (1.jpg, 2.jpg, 3.jpg, 4.jpg or any other) and select symbol types. \"\n",
        "        \"Annotated image uses color codes: red for valves, blue for pumps, green for sensors.\"\n",
        "    ),\n",
        "    theme=\"gradio/soft\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "kk1EzbO2lC1b",
        "outputId": "5a835797-ba05-443f-db93-be72793dc8cd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pipeline'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-740305894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1_class_agnostic_inference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStage1InferencePipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2_few_shot_inference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStage2FewShotInferencePipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "import json\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# Add the src directory to Python path to import pipeline modules\n",
        "sys.path.append('src')\n",
        "\n",
        "from  pipeline.stage1_class_agnostic_inference import Stage1InferencePipeline\n",
        "from pipeline.stage2_few_shot_inference import Stage2FewShotInferencePipeline\n",
        "\n",
        "# Define colors for each symbol type\n",
        "type_colors = {\n",
        "    \"valve\": \"red\",\n",
        "    \"pump\": \"blue\",\n",
        "    \"sensor\": \"green\",\n",
        "    \"default\": \"orange\"\n",
        "}\n",
        "\n",
        "class PIDDetectionInterface:\n",
        "    def __init__(self, config_path=\"src/pipeline/configs/config.yaml\"):\n",
        "        self.config_path = config_path\n",
        "        self.stage1_pipeline = None\n",
        "        self.stage2_pipeline = None\n",
        "        self.temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "    def initialize_pipelines(self):\n",
        "        \"\"\"Initialize the detection pipelines\"\"\"\n",
        "        try:\n",
        "            self.stage1_pipeline = Stage1InferencePipeline(config_path=self.config_path)\n",
        "            self.stage2_pipeline = Stage2FewShotInferencePipeline(config_path=self.config_path)\n",
        "            return True, \"Pipelines initialized successfully!\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Error initializing pipelines: {str(e)}\"\n",
        "\n",
        "    def process_image(self, image, detect_types, generate_code):\n",
        "        \"\"\"Main function to process uploaded image through the pipeline\"\"\"\n",
        "        if image is None:\n",
        "            return \"No image uploaded.\", image, None, \"\"\n",
        "\n",
        "        try:\n",
        "            # Save uploaded image to temporary location\n",
        "            temp_image_path = Path(self.temp_dir) / \"uploaded_image.jpg\"\n",
        "            image.save(temp_image_path)\n",
        "\n",
        "            # Initialize pipelines if not already done\n",
        "            if self.stage1_pipeline is None:\n",
        "                success, message = self.initialize_pipelines()\n",
        "                if not success:\n",
        "                    return f\"Pipeline Error: {message}\", image, None, \"\"\n",
        "\n",
        "            # Run Stage 1 detection\n",
        "            stage1_results = self.stage1_pipeline._infer_one_sheet(temp_image_path)\n",
        "\n",
        "            if not stage1_results:\n",
        "                return \"No symbols detected in the image.\", image, None, \"\"\n",
        "\n",
        "            # Run Stage 2 classification on detected crops\n",
        "            stage2_results = self.stage2_pipeline._classify_crops(temp_image_path, stage1_results)\n",
        "\n",
        "            # Process results\n",
        "            detections = self._format_detections(stage1_results, stage2_results)\n",
        "\n",
        "            # Filter by selected types\n",
        "            if detect_types:\n",
        "                detections = [d for d in detections if d['class'] in detect_types]\n",
        "\n",
        "            # Annotate image\n",
        "            annotated_image = self._annotate_image(image, detections)\n",
        "\n",
        "            # Create results table\n",
        "            df = pd.DataFrame(detections) if detections else pd.DataFrame()\n",
        "\n",
        "            # Generate summary\n",
        "            summary = self._generate_summary(detections)\n",
        "\n",
        "            # Generate IEC 61131 code if requested\n",
        "            code_output = \"\"\n",
        "            if generate_code and detections:\n",
        "                code_output = self._generate_iec_code(detections)\n",
        "\n",
        "            return summary, annotated_image, df, code_output\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing image: {str(e)}\", image, None, \"\"\n",
        "\n",
        "    def _format_detections(self, stage1_results, stage2_results):\n",
        "        \"\"\"Format detection results from both stages\"\"\"\n",
        "        detections = []\n",
        "\n",
        "        for i, (bbox, conf) in enumerate(stage1_results):\n",
        "            # Get classification result if available\n",
        "            class_name = \"unknown\"\n",
        "            class_conf = 0.0\n",
        "\n",
        "            if i < len(stage2_results):\n",
        "                class_name = stage2_results[i].get('class', 'unknown')\n",
        "                class_conf = stage2_results[i].get('confidence', 0.0)\n",
        "\n",
        "            detections.append({\n",
        "                'class': class_name,\n",
        "                'bbox': bbox,\n",
        "                'detection_confidence': conf,\n",
        "                'classification_confidence': class_conf,\n",
        "                'overall_confidence': (conf + class_conf) / 2\n",
        "            })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def _annotate_image(self, image, detections):\n",
        "        \"\"\"Draw bounding boxes and labels on the image\"\"\"\n",
        "        annotated = image.copy()\n",
        "        draw = ImageDraw.Draw(annotated)\n",
        "\n",
        "        for d in detections:\n",
        "            x1, y1, x2, y2 = map(int, d['bbox'])\n",
        "            color = type_colors.get(d['class'], type_colors['default'])\n",
        "\n",
        "            # Draw bounding box\n",
        "            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "\n",
        "            # Draw label\n",
        "            label = f\"{d['class']} ({int(d['overall_confidence']*100)}%)\"\n",
        "            draw.text((x1, y1-15), label, fill=color)\n",
        "\n",
        "        return annotated\n",
        "\n",
        "    def _generate_summary(self, detections):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        if not detections:\n",
        "            return \"No symbols detected.\"\n",
        "\n",
        "        # Count by type\n",
        "        type_counts = {}\n",
        "        for d in detections:\n",
        "            type_counts[d['class']] = type_counts.get(d['class'], 0) + 1\n",
        "\n",
        "        # Calculate average confidence\n",
        "        avg_conf = sum(d['overall_confidence'] for d in detections) / len(detections)\n",
        "\n",
        "        # Format summary\n",
        "        per_type_lines = \"\\n\".join([f\"• {t.title()}: {count}\" for t, count in type_counts.items()])\n",
        "\n",
        "        summary = f\"\"\"🔍 **Detection Results:**\n",
        "\n",
        "{per_type_lines}\n",
        "\n",
        "• **Total Symbols:** {len(detections)}\n",
        "• **Average Confidence:** {int(avg_conf * 100)}%\n",
        "• **Types Found:** {', '.join(sorted(type_counts.keys()))}\n",
        "\"\"\"\n",
        "        return summary\n",
        "\n",
        "    def _generate_iec_code(self, detections):\n",
        "        \"\"\"Generate basic IEC 61131-3 Structured Text code\"\"\"\n",
        "        if not detections:\n",
        "            return \"\"\n",
        "\n",
        "        # Group by type\n",
        "        sensors = [d for d in detections if d['class'] == 'sensor']\n",
        "        valves = [d for d in detections if d['class'] == 'valve']\n",
        "        pumps = [d for d in detections if d['class'] == 'pump']\n",
        "\n",
        "        code_lines = [\n",
        "            \"(* Auto-generated PLC Logic from P&ID *)\",\n",
        "            \"\",\n",
        "            \"VAR_INPUT\"\n",
        "        ]\n",
        "\n",
        "        # Add sensor inputs\n",
        "        for i, sensor in enumerate(sensors):\n",
        "            code_lines.append(f\"    Sensor_{i+1}: INT;  (* {sensor['class']} sensor *)\")\n",
        "\n",
        "        code_lines.extend([\n",
        "            \"    SetPoint: INT := 50;  (* Default setpoint *)\",\n",
        "            \"END_VAR\",\n",
        "            \"\",\n",
        "            \"VAR_OUTPUT\"\n",
        "        ])\n",
        "\n",
        "        # Add valve/pump outputs\n",
        "        for i, valve in enumerate(valves):\n",
        "            code_lines.append(f\"    Valve_{i+1}: BOOL;  (* {valve['class']} control *)\")\n",
        "\n",
        "        for i, pump in enumerate(pumps):\n",
        "            code_lines.append(f\"    Pump_{i+1}: BOOL;   (* {pump['class']} control *)\")\n",
        "\n",
        "        code_lines.extend([\n",
        "            \"END_VAR\",\n",
        "            \"\",\n",
        "            \"(* Basic Control Logic *)\"\n",
        "        ])\n",
        "\n",
        "        # Add basic control logic\n",
        "        if sensors and (valves or pumps):\n",
        "            code_lines.extend([\n",
        "                \"IF Sensor_1 < SetPoint THEN\",\n",
        "                \"    Valve_1 := TRUE;\" if valves else \"\",\n",
        "                \"    Pump_1 := TRUE;\" if pumps else \"\",\n",
        "                \"ELSE\",\n",
        "                \"    Valve_1 := FALSE;\" if valves else \"\",\n",
        "                \"    Pump_1 := FALSE;\" if pumps else \"\",\n",
        "                \"END_IF;\"\n",
        "            ])\n",
        "\n",
        "        return \"\\n\".join(line for line in code_lines if line is not None)\n",
        "\n",
        "# Create the interface instance\n",
        "pid_interface = PIDDetectionInterface()\n",
        "\n",
        "def detect_symbols_wrapper(image, detect_types, generate_code):\n",
        "    \"\"\"Wrapper function for Gradio interface\"\"\"\n",
        "    return pid_interface.process_image(image, detect_types, generate_code)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"AI-Powered P&ID Digitization & Code Generation\", theme=\"gradio/soft\") as interface:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔧 AI-Powered P&ID Digitization & IEC 61131 Code Generation\n",
        "\n",
        "    Upload a P&ID diagram to automatically detect symbols and optionally generate PLC control code.\n",
        "\n",
        "    **Features:**\n",
        "    - Stage 1: YOLO-based symbol detection\n",
        "    - Stage 2: Few-shot symbol classification\n",
        "    - IEC 61131-3 Structured Text code generation\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Input components\n",
        "            image_input = gr.Image(type=\"pil\", label=\"Upload P&ID Diagram\")\n",
        "\n",
        "            symbol_types = gr.CheckboxGroup(\n",
        "                choices=[\"valve\", \"pump\", \"sensor\"],\n",
        "                value=[\"valve\", \"pump\", \"sensor\"],\n",
        "                label=\"Symbol Types to Detect\"\n",
        "            )\n",
        "\n",
        "            generate_code_check = gr.Checkbox(\n",
        "                label=\"Generate IEC 61131-3 Code\",\n",
        "                value=False\n",
        "            )\n",
        "\n",
        "            detect_btn = gr.Button(\"🔍 Detect & Analyze\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            # Output components\n",
        "            summary_output = gr.Markdown(label=\"Detection Summary\")\n",
        "            annotated_image = gr.Image(label=\"Annotated P&ID\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Results table\n",
        "        results_table = gr.Dataframe(label=\"Detailed Detection Results\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Generated code output\n",
        "        code_output = gr.Code(\n",
        "            label=\"Generated IEC 61131-3 Structured Text\",\n",
        "            language=\"text\"\n",
        "        )\n",
        "\n",
        "    # Event handler\n",
        "    detect_btn.click(\n",
        "        fn=detect_symbols_wrapper,\n",
        "        inputs=[image_input, symbol_types, generate_code_check],\n",
        "        outputs=[summary_output, annotated_image, results_table, code_output]\n",
        "    )\n",
        "\n",
        "    # Example section\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## Instructions:\n",
        "    1. Upload a P&ID diagram image\n",
        "    2. Select which symbol types to detect\n",
        "    3. Check \"Generate IEC 61131-3 Code\" if you want PLC code output\n",
        "    4. Click \"Detect & Analyze\"\n",
        "\n",
        "    **Color coding:** Red = Valve, Blue = Pump, Green = Sensor\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3fef8f229f740a0ba5641edac015d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b8387316a443b389ef3e9c4d9d395c",
              "IPY_MODEL_68dec885d98948449762889f32fd1a4e",
              "IPY_MODEL_37220189acb54e5ca7452205e4ebdb87"
            ],
            "layout": "IPY_MODEL_966ee48c8e1e4bb1b37ab165450708a9"
          }
        },
        "23b8387316a443b389ef3e9c4d9d395c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_993587ebc4c94424b5e459108682a3d8",
            "placeholder": "​",
            "style": "IPY_MODEL_9a488e4839f144b79d95bc2694f86116",
            "value": "theme_schema%400.0.3.json: "
          }
        },
        "68dec885d98948449762889f32fd1a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19604add1a9f430982b6ccc85ec17435",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225e91e231874ca39ad6c18433cf14d7",
            "value": 1
          }
        },
        "37220189acb54e5ca7452205e4ebdb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a8cc3a358b4bb29736ee814359c79b",
            "placeholder": "​",
            "style": "IPY_MODEL_a0562f67dc74495fa2b210b88274aec5",
            "value": " 13.1k/? [00:00&lt;00:00, 225kB/s]"
          }
        },
        "966ee48c8e1e4bb1b37ab165450708a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993587ebc4c94424b5e459108682a3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a488e4839f144b79d95bc2694f86116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19604add1a9f430982b6ccc85ec17435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "225e91e231874ca39ad6c18433cf14d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a8cc3a358b4bb29736ee814359c79b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0562f67dc74495fa2b210b88274aec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}